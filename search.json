[
  {
    "objectID": "notebooks/ethena.html",
    "href": "notebooks/ethena.html",
    "title": "Ethena Dashboard",
    "section": "",
    "text": "Code\nimport json, warnings, os\nfrom pathlib import Path\n\nwarnings.filterwarnings('ignore')\n\nif Path.cwd().name == \"notebooks\":\n    rootdir = Path.cwd().parent\nelse:\n    rootdir = Path.cwd()\n\nimport pandas as pd\nimport plotly.express as px\nfrom plotly import graph_objects as go\n\nfrom stables.utils.postgres import get_sqlalchemy_engine\nfrom stables.config import local_pg_config, remote_pg_config\nengine = get_sqlalchemy_engine(local_pg_config)\n\nimport plotly.offline as pyo\npyo.init_notebook_mode(connected=True)"
  },
  {
    "objectID": "notebooks/ethena.html#tvl",
    "href": "notebooks/ethena.html#tvl",
    "title": "Ethena Dashboard",
    "section": "TVL",
    "text": "TVL\n\nTVL by stablecoins\n\n\nCode\nlatest_tvl_query = \"\"\"\nWITH latest_date AS (\n    SELECT MAX(DATE(time)) as max_date\n    FROM llama.circulating\n)\nSELECT \n    (SELECT max_date FROM latest_date) as latest_date,\n    SUM(CASE WHEN id = 146 THEN circulating ELSE 0 END) as tvl_usde,\n    SUM(CASE WHEN id = 221 THEN circulating ELSE 0 END) as tvl_usdtb\nFROM llama.circulating\nWHERE DATE(time) = (SELECT max_date FROM latest_date)\n\"\"\"\nlatest_tvl_df = pd.read_sql(latest_tvl_query, engine)\nlatest_date = latest_tvl_df['latest_date'].iloc[-1]\ntvl_usde = latest_tvl_df['tvl_usde'].iloc[-1]\ntvl_usdtb = latest_tvl_df['tvl_usdtb'].iloc[-1]\ntvl = tvl_usde + tvl_usdtb\n\n\ngrouped_query = \"\"\"\nWITH data AS (\n    SELECT \n        DATE(time) as date,\n        CASE \n            WHEN id = 146 THEN 'USDe'\n        WHEN id = 221 THEN 'USDTB'\n        ELSE CAST(id AS VARCHAR)\n    END as id,\n    SUM(circulating) as tvl\n    FROM llama.circulating\n    GROUP BY DATE(time), id\n    ORDER BY DATE(time), id\n),\nsorted_data AS (\n    SELECT \n        date,\n        id,\n        tvl,\n        ROW_NUMBER() OVER (PARTITION BY date, id ORDER BY date DESC) as rn\n    FROM data\n)\nSELECT \n    date,\n    id,\n    tvl\nFROM sorted_data\nWHERE rn = 1\nORDER BY date, id\n\"\"\"\ndf = pd.read_sql(grouped_query, engine)\n\nfig = px.bar(df, x=\"date\", y=\"tvl\", color=\"id\", title=f\"Current TVL: {tvl/1e9:.2f}B, USDe: {tvl_usde/1e9:.2f}B, USDTB: {tvl_usdtb/1e9:.2f}B\",labels=\"\")\nfig.update_layout(\n    xaxis_title=\"Date\",\n    yaxis_title=\"TVL (USD)\",\n    legend_title_text=\"Stablecoin\"\n)\nfig.show()\n\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\nTVL by chains\n\n\nCode\nquery = \"\"\"\nWITH data AS (\n    SELECT \n        DATE(time) as date,\n        chain,\n        SUM(circulating) as tvl\n    FROM llama.circulating\n    GROUP BY DATE(time), chain\n),\nsorted_data AS (\n    SELECT \n        date,\n        chain,\n        tvl,\n        ROW_NUMBER() OVER (PARTITION BY date, chain ORDER BY date DESC) as rn\n    FROM data\n)\nSELECT \n    date,\n    chain,\n    tvl\nFROM sorted_data\nWHERE rn = 1\nORDER BY date, chain\n\"\"\"\n\ndf = pd.read_sql(query, engine)\n\nfig = px.bar(df, x=\"date\", y=\"tvl\", color=\"chain\", title=\"Ethena TVL by chains\")\nfig.update_layout(\n    xaxis_title=\"Date\",\n    yaxis_title=\"TVL (USD)\",\n    legend_title_text=\"Chain\"\n)\nfig.show()\n\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json"
  },
  {
    "objectID": "notebooks/ethena.html#usde",
    "href": "notebooks/ethena.html#usde",
    "title": "Ethena Dashboard",
    "section": "USDe",
    "text": "USDe\n\nTVL\n\n\nCode\nquery = \"\"\"\nSELECT * FROM llama.circulating\nWHERE id = 146\n\"\"\"\ndf= pd.read_sql(query, engine)\n\nl = df['time'].max()\n\ntvl = df[(df['time'] == l)]['circulating'].sum()\n\nn_chains = df[\n    (df['time'] == l) \n]['chain'].nunique()\n\n\ndf = df.groupby(['time', \"chain\"]).agg(\n    tvl=('circulating', 'sum')\n).reset_index()\ndf\n\nfig = px.bar(df, x=\"time\", y=\"tvl\", color=\"chain\", title=f\"{l.date()}, TVL: {tvl/1e9:.2f}B\", )\nfig.update_layout(\n    xaxis_title=\"Date\",\n    yaxis_title=\"TVL (USD)\",\n    legend_title_text=\"Chain\"\n)\nfig.show()\n\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\nPrimary market\nMint and Redeem\n\n\nCode\nquery = \"\"\"\nWITH combined_events AS (\n    SELECT\n        contract_address,\n        block_timestamp,\n        benefactor,\n        beneficiary,\n        caller,\n        collateral_asset,\n        collateral_amount,\n        event_type,\n        CASE \n            WHEN event_type = 'mint' THEN usde_amount \n            ELSE -usde_amount \n        END as usde_amount\n    FROM ethena_.usde_mint_redeem_v1_events\n\n    UNION ALL\n\n    SELECT \n        contract_address,\n        block_timestamp,\n        benefactor,\n        beneficiary,\n        caller,\n        collateral_asset,\n        collateral_amount,\n        event_type,\n        CASE \n            WHEN event_type = 'mint' THEN usde_amount \n            ELSE -usde_amount \n        END as usde_amount\n    FROM ethena_.usde_mint_redeem_v2_events\n),\n\ndaily_totals AS (\n    SELECT \n        DATE(block_timestamp) as date,\n        event_type,\n        SUM(usde_amount) as usde_amount\n    FROM combined_events\n    GROUP BY DATE(block_timestamp), event_type\n),\n\ndaily_pivot AS (\n    SELECT \n        date,\n        SUM(CASE WHEN event_type = 'mint' THEN usde_amount ELSE 0 END) as mint,\n        SUM(CASE WHEN event_type = 'redeem' THEN usde_amount ELSE 0 END) as redeem,\n        SUM(usde_amount) as net_change\n    FROM daily_totals\n    GROUP BY date\n)\n\nSELECT \n    date,\n    mint / 1e18 as mint,\n    redeem / 1e18 as redeem,\n    net_change / 1e18 as net_change\nFROM daily_pivot\nORDER BY date;\n\"\"\"\ndf= pd.read_sql(query, engine)\n\n# Create the plot\nfig = go.Figure()\n\n# Add mint bars\nfig.add_trace(go.Bar(\n    x=df.index,\n    y=df['mint'],\n    name='Mint',\n    marker_color='green',\n    # opacity=0.7\n))\n\n# Add redeem bars\nfig.add_trace(go.Bar(\n    x=df.index,\n    y=df['redeem'],\n    name='Redeem',\n    marker_color='red',\n    # opacity=0.7\n))\n\n# Add net change line\nfig.add_trace(go.Scatter(\n    x=df.index,\n    y=df['net_change'],\n    name='Net Change',\n    mode='lines',\n    line=dict(color='blue', width=1),\n    # marker=dict(size=2),\n    opacity=0.7\n))\n\n# Update layout\nfig.update_layout(\n    title='Daily USDE Mint/Redeem Activities',\n    xaxis_title='Date',\n    yaxis_title='Amount (USDE)',\n    barmode='group',\n    hovermode='x unified'\n)\n\n# Show the plot\nfig.show() \n\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\n\n\nUSDe staking\n\n\nCode\nquery = \"\"\"\nWITH usde_data AS (\n    SELECT \n        DATE(time) as date,\n        SUM(circulating) as usde\n    FROM llama.circulating\n    WHERE id = 146\n    GROUP BY DATE(time)\n),\nsusde_data AS (\n    SELECT \n        DATE(time) as date,\n        tvl_usd as susde\n    FROM llama.yield_pools\n    WHERE pool_id = '66985a81-9c51-46ca-9977-42b4fe7bc6df'\n),\ncombined_data AS (\n    SELECT \n        COALESCE(u.date, s.date) as date,\n        u.usde,\n        s.susde\n    FROM usde_data u\n    FULL OUTER JOIN susde_data s ON u.date = s.date\n),\nranked_data AS (\n    SELECT \n        date,\n        usde,\n        susde,\n        CASE \n            WHEN usde IS NOT NULL AND usde &gt; 0 \n            THEN (susde / usde) * 100 \n            ELSE NULL \n        END as staking_perc,\n        ROW_NUMBER() OVER (PARTITION BY date ORDER BY date DESC) as rn\n    FROM combined_data\n)\nSELECT \n    date,\n    usde,\n    susde,\n    staking_perc\nFROM ranked_data\nWHERE rn = 1\nORDER BY date\n\"\"\"\ndf = pd.read_sql(query, engine)\ncurrent_staking_perc = df[df['date'] == df['date'].max()]['staking_perc'].values[0]\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=df['date'], y=df['usde'], name='USDe', opacity=0.5, yaxis='y'))\n\nfig.add_trace(go.Scatter(\n      x=df['date'],\n      y=df['staking_perc'],\n      mode='lines',\n      name='Staking %',\n      yaxis='y2'\n  ))\nfig.update_layout(\n      yaxis2=dict(\n          title=\"%\",\n          overlaying='y',\n          side='right'\n      ),\n    # title=\"Current USDe TVL: {:.2f}B, staking {:.2f}%\".format(tvl_usde/1e9, current_staking_perc),\n    xaxis_title=\"Date\",\n    yaxis_title=\"TVL (USD)\",\n  )\n\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stables research",
    "section": "",
    "text": "Dashboard"
  },
  {
    "objectID": "index.html#yield-bearing",
    "href": "index.html#yield-bearing",
    "title": "Stables research",
    "section": "",
    "text": "Dashboard"
  },
  {
    "objectID": "CLAUDE.html",
    "href": "CLAUDE.html",
    "title": "CLAUDE.md",
    "section": "",
    "text": "This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.\n\n\nThis project uses uv for Python package management and PostgreSQL as the data warehouse. To set up the development environment:\nuv sync\n# Set up PostgreSQL (see docs/postgres_setup.md for detailed instructions)\n# Update .env file with PostgreSQL connection details and Etherscan API key\n\n\n\n\n\n\nRun dlt pipeline: python scripts/curve_dlt_pipeline.py - Fetches Curve Finance event logs and loads into PostgreSQL raw_curve schema\nRun dbt transformations:\ncd dbt_subprojects/curve\nuv run dbt run\nThis transforms raw data and saves to PostgreSQL crvusd_market schema\n\n\n\n\n\nInstall dependencies: uv sync\nStart Jupyter: uv run jupyter notebook or uv run jupyter lab\nGenerate website: quarto render (for the Quarto website defined in _quarto.yml)\n\n\n\n\n\nThis is an ELT (Extract, Load, Transform) data pipeline for stablecoin research:\n\nExtract & Load: Python scripts using dlt library fetch blockchain data from Etherscan API and load into PostgreSQL database\nTransform: dbt transforms raw data into analytics-ready tables using SQL\nAnalysis: Jupyter notebooks for data analysis and visualization\n\n\n\n\nscripts/: DLT pipeline scripts for data ingestion (e.g., curve_dlt_pipeline.py for Curve Finance data)\ndbt_subprojects/: DBT projects for data transformation, each with their own dbt_project.yml\nsrc/stables/data/source/: Python modules for different data sources (etherscan, defillama, coingecko)\ndata/address/: Configuration files with contract addresses and pool definitions\ndocs/: Documentation including PostgreSQL setup guide\n\n\n\n\n\nDLT pipelines extract blockchain logs and load into PostgreSQL raw schemas (e.g., raw_curve, raw_ethena)\nDBT models in dbt_subprojects/*/models/ transform raw data\nTransformed data is saved to PostgreSQL staging schemas (e.g., crvusd_market, usde)\nAnalysis notebooks consume both raw and staged data from PostgreSQL\n\n\n\n\n\nPostgreSQL Database: Single database stables with multiple schemas:\n\nraw_curve, raw_ethena - Raw data from DLT pipelines\ncrvusd_market, usde - Staged data from DBT transformations\nusde_marts - Analytics/marts tables\n\nDBT profiles: Each subproject has its own profiles.yml configuration pointing to PostgreSQL\nConnection: Configured via environment variables in .env file\n\n\n\n\n\n\nPython 3.11+ with uv package manager\nDLT (Data Load Tool) for robust data ingestion pipelines\nDBT (Data Build Tool) for SQL-based data transformations\nPostgreSQL as the data warehouse\nJupyter for analysis notebooks\nQuarto for website generation\nEtherscan API as primary blockchain data source\n\n\n\n\nSee docs/postgres_setup.md for detailed instructions on setting up PostgreSQL with Docker or local installation."
  },
  {
    "objectID": "CLAUDE.html#environment-setup",
    "href": "CLAUDE.html#environment-setup",
    "title": "CLAUDE.md",
    "section": "",
    "text": "This project uses uv for Python package management and PostgreSQL as the data warehouse. To set up the development environment:\nuv sync\n# Set up PostgreSQL (see docs/postgres_setup.md for detailed instructions)\n# Update .env file with PostgreSQL connection details and Etherscan API key"
  },
  {
    "objectID": "CLAUDE.html#common-commands",
    "href": "CLAUDE.html#common-commands",
    "title": "CLAUDE.md",
    "section": "",
    "text": "Run dlt pipeline: python scripts/curve_dlt_pipeline.py - Fetches Curve Finance event logs and loads into PostgreSQL raw_curve schema\nRun dbt transformations:\ncd dbt_subprojects/curve\nuv run dbt run\nThis transforms raw data and saves to PostgreSQL crvusd_market schema\n\n\n\n\n\nInstall dependencies: uv sync\nStart Jupyter: uv run jupyter notebook or uv run jupyter lab\nGenerate website: quarto render (for the Quarto website defined in _quarto.yml)"
  },
  {
    "objectID": "CLAUDE.html#architecture-overview",
    "href": "CLAUDE.html#architecture-overview",
    "title": "CLAUDE.md",
    "section": "",
    "text": "This is an ELT (Extract, Load, Transform) data pipeline for stablecoin research:\n\nExtract & Load: Python scripts using dlt library fetch blockchain data from Etherscan API and load into PostgreSQL database\nTransform: dbt transforms raw data into analytics-ready tables using SQL\nAnalysis: Jupyter notebooks for data analysis and visualization\n\n\n\n\nscripts/: DLT pipeline scripts for data ingestion (e.g., curve_dlt_pipeline.py for Curve Finance data)\ndbt_subprojects/: DBT projects for data transformation, each with their own dbt_project.yml\nsrc/stables/data/source/: Python modules for different data sources (etherscan, defillama, coingecko)\ndata/address/: Configuration files with contract addresses and pool definitions\ndocs/: Documentation including PostgreSQL setup guide\n\n\n\n\n\nDLT pipelines extract blockchain logs and load into PostgreSQL raw schemas (e.g., raw_curve, raw_ethena)\nDBT models in dbt_subprojects/*/models/ transform raw data\nTransformed data is saved to PostgreSQL staging schemas (e.g., crvusd_market, usde)\nAnalysis notebooks consume both raw and staged data from PostgreSQL\n\n\n\n\n\nPostgreSQL Database: Single database stables with multiple schemas:\n\nraw_curve, raw_ethena - Raw data from DLT pipelines\ncrvusd_market, usde - Staged data from DBT transformations\nusde_marts - Analytics/marts tables\n\nDBT profiles: Each subproject has its own profiles.yml configuration pointing to PostgreSQL\nConnection: Configured via environment variables in .env file"
  },
  {
    "objectID": "CLAUDE.html#technology-stack",
    "href": "CLAUDE.html#technology-stack",
    "title": "CLAUDE.md",
    "section": "",
    "text": "Python 3.11+ with uv package manager\nDLT (Data Load Tool) for robust data ingestion pipelines\nDBT (Data Build Tool) for SQL-based data transformations\nPostgreSQL as the data warehouse\nJupyter for analysis notebooks\nQuarto for website generation\nEtherscan API as primary blockchain data source"
  },
  {
    "objectID": "CLAUDE.html#postgresql-setup",
    "href": "CLAUDE.html#postgresql-setup",
    "title": "CLAUDE.md",
    "section": "",
    "text": "See docs/postgres_setup.md for detailed instructions on setting up PostgreSQL with Docker or local installation."
  }
]